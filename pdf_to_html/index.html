<!DOCTYPE html>
<html lang="es">





<head>
  <meta property="og:url" content="https://imlauera.github.io/pdf_to_html/">
  <meta property="og:site_name" content="Imlauer">
  <meta property="og:title" content="PDF to html">
  <meta property="og:description" content="Actualizaci√≥n: Mir√° lo que hizo el loco este para escanear un diccionario de Gregg en ingl√©s.
https://github.com/richyliu/greggdict/blob/master/format/README.md
Diccionario de Taquigraf√≠a Esquema del proceso de OCR El proceso para obtener las palabras y sus posiciones a partir de las fotos originales es bastante complicado. A continuaci√≥n, un resumen del proceso:
Paso 0: Limpiar las im√°genes No lo hice al principio, pero esto mejorar√≠a mucho los resultados del OCR. Blanquear las im√°genes y aumentar el contraste y la nitidez usando una herramienta como ImageMagick.">
  <meta property="og:locale" content="es_es">
  <meta property="og:type" content="article">
    <meta property="article:published_time" content="2026-02-16T15:41:58-03:00">
    <meta property="article:modified_time" content="2026-02-16T15:41:58-03:00">
    <meta property="article:tag" content="Ai">

  
  <meta itemprop="name" content="PDF to html">
  <meta itemprop="description" content="Actualizaci√≥n: Mir√° lo que hizo el loco este para escanear un diccionario de Gregg en ingl√©s.
https://github.com/richyliu/greggdict/blob/master/format/README.md
Diccionario de Taquigraf√≠a Esquema del proceso de OCR El proceso para obtener las palabras y sus posiciones a partir de las fotos originales es bastante complicado. A continuaci√≥n, un resumen del proceso:
Paso 0: Limpiar las im√°genes No lo hice al principio, pero esto mejorar√≠a mucho los resultados del OCR. Blanquear las im√°genes y aumentar el contraste y la nitidez usando una herramienta como ImageMagick.">
  <meta itemprop="datePublished" content="2026-02-16T15:41:58-03:00">
  <meta itemprop="dateModified" content="2026-02-16T15:41:58-03:00">
  <meta itemprop="wordCount" content="1762">
  <meta itemprop="keywords" content="Ai">
  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="PDF to html">
  <meta name="twitter:description" content="Actualizaci√≥n: Mir√° lo que hizo el loco este para escanear un diccionario de Gregg en ingl√©s.
https://github.com/richyliu/greggdict/blob/master/format/README.md
Diccionario de Taquigraf√≠a Esquema del proceso de OCR El proceso para obtener las palabras y sus posiciones a partir de las fotos originales es bastante complicado. A continuaci√≥n, un resumen del proceso:
Paso 0: Limpiar las im√°genes No lo hice al principio, pero esto mejorar√≠a mucho los resultados del OCR. Blanquear las im√°genes y aumentar el contraste y la nitidez usando una herramienta como ImageMagick.">

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>
    
    PDF to html
    
  </title>
  <link rel="stylesheet" href='https://imlauera.github.io/css/site.min.css'>
  <link rel="canonical" href="https://imlauera.github.io/pdf_to_html/">
  <link rel="alternate" type="application/rss&#43;xml" href="https://imlauera.github.io/index.xml" title="Imlauer">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="referrer" content="no-referrer">
  <meta name="author" content="Imlauer.">
  <meta name="description" content="Actualizaci√≥n: Mir√° lo que hizo el loco este para escanear un diccionario de Gregg en ingl√©s.
https://github.com/richyliu/greggdict/blob/master/format/README.md
Diccionario de Taquigraf√≠a
Esquema del proceso de OCR
El proceso para obtener las palabras y sus posiciones a partir de las fotos originales es bastante complicado. A continuaci√≥n, un resumen del proceso:

Paso 0: Limpiar las im√°genes
No lo hice al principio, pero esto mejorar√≠a mucho los resultados del OCR.
Blanquear las im√°genes y aumentar el contraste y la nitidez usando una herramienta como ImageMagick.">
</head>
<body><nav class="navbar is-transparent " role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a class="navbar-item" href="https://imlauera.github.io/">
      <figure class="image">
        <img alt="" class="is-rounded" src="/img/memememe.jpg">
      </figure>
    </a>
    <a class="navbar-item" href="https://imlauera.github.io/">
      Imlauer
    </a>
    <a class="navbar-item" href="/acerca/">
      Acerca de Mi
    </a>
  </div>
  
  
</nav>

  <section>
    <section class='hero is-small is-link is-fullwidth'>
      <div class="hero-body">
<div class="container">
  <h1 class="title">
    PDF to html
  </h1>
  <h2 class="subtitle">
    <time datetime='2026-02-16T15:41:58-03:00'>
      February 16, 2026
    </time>
    
    <br>
    
    
    
    <a class="tag is-info" href="https://imlauera.github.io/tags/ai/">Ai</a>
    
    
    
  </h2>
</div>

      </div>
    </section>
    <section class="section">
      <div class="container">
<div class="content is-medium">
  <p>Actualizaci√≥n: Mir√° lo que hizo el loco este para escanear un diccionario de Gregg en ingl√©s.</p>
<p><a href="https://github.com/richyliu/greggdict/blob/master/format/README.md">https://github.com/richyliu/greggdict/blob/master/format/README.md</a></p>
<h1 id="diccionario-de-taquigraf√≠a">Diccionario de Taquigraf√≠a</h1>
<h2 id="esquema-del-proceso-de-ocr">Esquema del proceso de OCR</h2>
<p>El proceso para obtener las palabras y sus posiciones a partir de las fotos originales es bastante complicado. A continuaci√≥n, un resumen del proceso:</p>
<hr>
<h3 id="paso-0-limpiar-las-im√°genes">Paso 0: Limpiar las im√°genes</h3>
<p>No lo hice al principio, pero esto mejorar√≠a mucho los resultados del OCR.
Blanquear las im√°genes y aumentar el contraste y la nitidez usando una herramienta como <strong>ImageMagick</strong>.</p>
<hr>
<h3 id="paso-1-escanear-con-google-cloud-vision">Paso 1: Escanear con Google Cloud Vision</h3>
<p>Usar el procesamiento as√≠ncrono por lotes de im√°genes de <strong>Google Cloud Vision</strong> para obtener el texto de todas las im√°genes.
Utilizar el reconocimiento <code>TEXT_DETECTION</code>, ya que hay poco texto en las p√°ginas.</p>
<hr>
<h3 id="paso-2-an√°lisis-exploratorio">Paso 2: An√°lisis exploratorio</h3>
<p>Visualizar los datos con <code>index.js</code>, que depende de <code>main.js</code>.
Abrir <code>index.html</code>, que dibuja la p√°gina y las superposiciones de los cuadros de texto sobre un canvas.
Esto permite determinar la mejor forma de extraer el texto √∫til.</p>
<hr>
<h3 id="paso-3-extracci√≥n-a-json-preliminar-formato-2">Paso 3: Extracci√≥n a JSON preliminar (formato 2)</h3>
<p>Ejecutar <code>run.js</code>, asegur√°ndose de correr la funci√≥n <code>moveToFormat2</code> para convertir el JSON escaneado original en un JSON m√°s utilizable.</p>
<p>Este archivo contiene:</p>
<ul>
<li>La posici√≥n (un solo par de coordenadas) de cada palabra en el diccionario.</li>
<li>Un intento de correcci√≥n autom√°tica de errores.</li>
</ul>
<h4 id="errores-conocidos">Errores conocidos</h4>
<p>Hay varios errores molestos en el JSON escaneado original:</p>
<ul>
<li>
<p>Algunas letras se reconocen como caracteres cir√≠licos, que se ven id√©nticos a letras en ingl√©s, pero tienen un c√≥digo Unicode muy alto (&gt;150).
Esto se corrige usando una tabla de equivalencias (<code>confusables.json</code>), proveniente de Unicode.</p>
</li>
<li>
<p>Tambi√©n hay ‚Äúbasura‚Äù extra al final de algunas palabras.
Esto se corrige en el paso 5.</p>
</li>
</ul>
<h4 id="correcci√≥n-de-errores">Correcci√≥n de errores</h4>
<p>La correcci√≥n se realiza eliminando letras desde el inicio de la palabra hasta que encaje alfab√©ticamente con las palabras que la rodean.</p>
<hr>
<h3 id="paso-4-correcci√≥n-manual-de-errores">Paso 4: Correcci√≥n manual de errores</h3>
<p>Los archivos JSON en formato 2 se cargan y los errores se corrigen manualmente usando <code>corrector.html</code> (y su correspondiente <code>corrector.js</code>).</p>
<p>Es importante guardar y respaldar peri√≥dicamente el archivo <code>format.json</code> mientras se realizan las correcciones.</p>
<p>Algunas palabras pueden faltar; en ese caso, deben agregarse manualmente al JSON de salida.</p>
<hr>
<h3 id="paso-5-detecci√≥n-de-errores-ortogr√°ficos">Paso 5: Detecci√≥n de errores ortogr√°ficos</h3>
<p>Todos los archivos est√°n en <code>format3/</code>.</p>
<ol>
<li>Se extraen las palabras en <code>wordlist</code>.</li>
<li>Se comparan contra un diccionario local (que puede no estar completo).</li>
</ol>
<ul>
<li>Solo se verifican palabras en min√∫sculas y alfab√©ticas.</li>
<li>Las que no pasan la verificaci√≥n van a <code>notindict</code>.</li>
<li>Las que no se verifican van a <code>nonloweralpha</code>.</li>
</ul>
<p>Las palabras no verificadas se revisan si contienen solo caracteres alfab√©ticos (min√∫sculas y may√∫sculas):</p>
<ul>
<li>Las que no pasan ‚Üí <code>notindict_upperalpha</code></li>
<li>Las que contienen caracteres no alfab√©ticos ‚Üí <code>nonalpha</code></li>
</ul>
<p>En este punto hay tres archivos con palabras mal escritas:</p>
<ul>
<li><code>nonalpha</code></li>
<li><code>notindict_upperalpha</code></li>
<li><code>notindict</code> (para min√∫sculas)</li>
</ul>
<p>Muchas palabras terminan en puntuaci√≥n ‚Äúbasura‚Äù.
Estas se dividen en:</p>
<ul>
<li><code>nonalpha_endsinpunc</code></li>
<li><code>nonalpha_endsnotpunc</code></li>
</ul>
<p>(derivados de <code>nonalpha</code>)</p>
<p>La ortograf√≠a se verifica usando una herramienta online (PhraseFinder.com).
El archivo utilizado es <code>phrasechecker.js</code>.</p>
<p>Se ejecuta para cada uno de estos archivos:</p>
<ul>
<li><code>nonalpha_endsinpunc</code></li>
<li><code>nonalpha_endsnotpunc</code></li>
<li><code>nonalpha</code></li>
<li><code>notindict_upperalpha</code></li>
<li><code>notindict</code></li>
</ul>
<p>Los resultados se guardan en archivos con el prefijo <code>pf_</code>.</p>
<p>Las palabras que no son ASCII se asumen autom√°ticamente como frases no inglesas.</p>
<p>Las palabras en <code>nonalpha_endsinpunc</code> se corrigen eliminando la puntuaci√≥n final (cualquier car√°cter distinto de <code>a-z</code> al final de la palabra).
Aun as√≠, quedan algunas palabras inv√°lidas.
Algunas terminadas en <code>-</code> deben corregirse manualmente.</p>
<hr>
<h3 id="paso-6-correcci√≥n-manual-final">Paso 6: Correcci√≥n manual final</h3>
<p>Hay aproximadamente 250 palabras que deben corregirse manualmente.
Esto se hace usando <code>fixer.html</code> y <code>fixer.js</code>, que funcionan de manera similar a <code>corrector</code>.</p>
<p>Los archivos relevantes est√°n en <code>format4/</code>.</p>
<hr>
<h3 id="paso-7-limpieza-final">Paso 7: Limpieza final</h3>
<p>Se corrigen los n√∫meros de archivo para que coincidan con el n√∫mero real de p√°gina.</p>
<p>El resultado final est√° en <code>format5/</code>, que tambi√©n incluye las im√°genes renombradas.</p>
<h1 id="shorthand-dictionary">Shorthand Dictionary</h1>
<h2 id="ocr-process-outline">OCR process outline</h2>
<p>The process for getting the words and their positions from the raw photos is
quite complicated. Here is an outline of that process in brief</p>
<h3 id="step-0-clean-the-images">Step 0: Clean the images</h3>
<p>I didn&rsquo;t do this initially, but this would greatly improve OCR results. Whiten
the images and increase the contrast and sharpness using a tool like imagemagick</p>
<h3 id="step-1-scan-with-google-cloud-vision">Step 1: Scan with Google Cloud Vision</h3>
<p>Use Google Cloud Vision&rsquo;s asynchronous batch image processing to get the text of
all the images. Use <code>TEXT_DECTECTION</code> recognition, since there is sparse text on
the pages</p>
<h3 id="step-2-exploratory-analysis">Step 2: Exploratory analysis</h3>
<p>Visualize the data with <code>index.js</code>, which depends on <code>main.js</code>. Open up
<code>index.html</code>, which draws the page and the text box overlays on a canvas. This
can be used to determine how best to extract the useful text.</p>
<h3 id="step-3-extraction-into-preliminary-json-format-2">Step 3: Extraction into preliminary JSON (format 2)</h3>
<p>Run <code>run.js</code>, making sure to run the <code>moveToFormat2</code> function to convert the
raw scanned JSON into more usable JSON. This contains the position (just one
pair of coordinates) of each word in the dictionary as well as some of its best
effort error correction.</p>
<h4 id="know-errors">Know errors</h4>
<p>There are several annoying errors in the raw scanned JSON. The first is that
some letters are scanned as Cyrillic characters, which appear identical to
English letters with the exception that their char code point is extremely large
(&gt; 150). This is corrected by using a lookup table (<code>confusables.json</code>), which
is from UNICODE. Another error is that there is extraneous &ldquo;junk&rdquo; at the end of
a word. This is dealt with in step 5</p>
<h4 id="error-correction">Error correction</h4>
<p>Error correction is done by removing letters from the start of the word until it
fits in alphabetically with the surrounding words.</p>
<h3 id="step-4-manual-error-correction">Step 4: Manual error correction</h3>
<p>The format 2 JSON files are loaded and errors are manually corrected using
<code>corrector.html</code> (and the corresponding <code>corrector.js</code>). Periodically save and
back up the <code>format.json</code> file while going through the corrections.</p>
<p>Some words may be missing, in which case manually add them to the output JSON.</p>
<h3 id="step-5-word-spelling-error-detection">Step 5: Word spelling error detection</h3>
<p>All the files are in <code>format3/</code>. First the words are extracted into <code>wordlist</code>.
Then they are checked against a local dictionary (which may not be complete).
Only lowercase alpha words are checked, and the ones that do not pass are put
into <code>notindict</code>. The words that are not checked are put into <code>nonloweralpha</code>.
Those unchecked words are checked against the dictionary if they contain only
alpha characters (lower and uppercase). The ones that do not pass are put into
<code>notindict_upperalpha</code> and the ones that are contain non alpha characters are
put into <code>nonalpha</code>. At this stage there are three files that contain words that
are not spelled correctly: <code>nonalpha</code>, <code>notindict_upperalpha</code>, and <code>notindict</code>
(for lower alpha).</p>
<p>There are a lot of words which end in &ldquo;junk&rdquo; punctuation. Those have been split
into <code>nonalpha_endsinpunc</code> while the rest are in <code>nonalpha_endsnotpunc</code>. (This
is from <code>nonalpha</code>)</p>
<p>The spelling of words is checked using an online lookup tool (PhraseFinder.com).
The file for doing this is <code>phrasechecker.js</code>. It is run for each of the 4
files: <code>nonalpha_endsinpunc</code>, <code>nonalpha_endsnotpunc</code>, <code>nonalpha</code>,
<code>notindict_upperalpha</code>, <code>notindict</code> and the result goes into another file with
<code>pf_</code> as the prefix. Non ASCII words are automatically assumed to be non English
phrases.</p>
<p>The words in <code>nonalpha_endsinpunc</code> are fixed by removing the ending
&ldquo;punctuation&rdquo; (really anything besides <code>a-z</code> that the word ends in). There are
still a few words after which still are not valid. There are a few words with
end in <code>-</code> that need to be fixed manually.</p>
<h3 id="step-6-manual-fixing">Step 6: Manual fixing</h3>
<p>There are about 250 words that need to be fixed manually. This is done using
<code>fixer.html</code> and <code>fixer.js</code>. It is structured similarly to corrector. The
relevant files are in <code>format4/</code></p>
<h3 id="step-7-final-clean-up">Step 7: Final clean up</h3>
<p>The file numbers are corrected (to match the actual page number). The output is
in <code>format5/</code>, which includes the images renamed as well.</p>
<hr>
<h2 id="viejo-no-usar">Viejo no usar</h2>
<p>Dame el codigo de python que pasa de un pdf a texto del diccionario que contiene los simbolos el diccionario empieza en la pagina numero 5. El simbolo esta a la iazquierda y la palabra a la derecha quiero que el script me genere un archivo html en donde pueda hacer control +f y buscar la palabra (tenes que pasar la imagen a texto ) pero el simbolo dejalo como texto, no se si me entendes si queres mas informacion pedime, otro dato mas son 3 columnas y a veces hay palabras que se escriben en 2 renglones pero son 1 como por ejemplo administra- y abajo dor seria administrador, dame a mi el codigo y yo lo ejecuto en mi computadora</p>
<p>Perfecto, ahora entiendo mejor. Son <strong>3 columnas</strong> y necesitas manejar las palabras que se dividen en dos renglones (con gui√≥n). Te voy a dar el c√≥digo completo y optimizado:Perfecto! Te acabo de crear el script completo. Aqu√≠ te explico lo que hace:</p>
<h2 id="-caracter√≠sticas-del-script">üéØ Caracter√≠sticas del Script</h2>
<ol>
<li><strong>Maneja 3 columnas</strong> por p√°gina</li>
<li><strong>Une palabras divididas</strong>: &ldquo;administra-&rdquo; + &ldquo;dor&rdquo; ‚Üí &ldquo;administrador&rdquo;</li>
<li><strong>S√≠mbolos como im√°genes</strong> (columna izquierda)</li>
<li><strong>Palabras como texto OCR</strong> (columna derecha)</li>
<li><strong>HTML con b√∫squeda</strong> Ctrl+F y cuadro de b√∫squeda</li>
</ol>
<h2 id="-dependencias-que-necesitas-instalar">üì¶ Dependencias que necesitas instalar</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pip install PyMuPDF pillow pytesseract
</span></span></code></pre></div><p>Y tambi√©n necesitas instalar <strong>Tesseract OCR</strong>:</p>
<ul>
<li><strong>Windows</strong>: Descarga desde <a href="https://github.com/UB-Mannheim/tesseract/wiki">https://github.com/UB-Mannheim/tesseract/wiki</a></li>
<li><strong>Mac</strong>: <code>brew install tesseract tesseract-lang</code></li>
<li><strong>Linux</strong>: <code>sudo apt-get install tesseract-ocr tesseract-ocr-spa</code></li>
</ul>
<h2 id="-c√≥mo-usar-el-script">üöÄ C√≥mo usar el script</h2>
<ol>
<li>Coloca el PDF en la misma carpeta que el script</li>
<li>Ejecuta: <code>python diccionario_pdf_to_html.py</code></li>
<li>Abre el archivo <code>diccionario_taquigrafico.html</code> en tu navegador</li>
</ol>
<h2 id="-ajustes-importantes">‚öôÔ∏è Ajustes importantes</h2>
<p>Si las columnas no se detectan bien, ajusta estos valores en la l√≠nea 128-134:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>columns_config <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Columna 1</span>
</span></span><span style="display:flex;"><span>    {<span style="color:#e6db74">&#39;symbol&#39;</span>: (<span style="color:#ae81ff">0.02</span>, <span style="color:#ae81ff">0.12</span>), <span style="color:#e6db74">&#39;text&#39;</span>: (<span style="color:#ae81ff">0.12</span>, <span style="color:#ae81ff">0.32</span>)},
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Columna 2</span>
</span></span><span style="display:flex;"><span>    {<span style="color:#e6db74">&#39;symbol&#39;</span>: (<span style="color:#ae81ff">0.35</span>, <span style="color:#ae81ff">0.45</span>), <span style="color:#e6db74">&#39;text&#39;</span>: (<span style="color:#ae81ff">0.45</span>, <span style="color:#ae81ff">0.65</span>)},
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Columna 3</span>
</span></span><span style="display:flex;"><span>    {<span style="color:#e6db74">&#39;symbol&#39;</span>: (<span style="color:#ae81ff">0.68</span>, <span style="color:#ae81ff">0.78</span>), <span style="color:#e6db74">&#39;text&#39;</span>: (<span style="color:#ae81ff">0.78</span>, <span style="color:#ae81ff">0.98</span>)}
</span></span><span style="display:flex;"><span>]
</span></span></code></pre></div><p>Los n√∫meros representan el porcentaje del ancho de la p√°gina (de 0 a 1).¬°Listo! El script est√° disponible para descargar. Cualquier duda sobre c√≥mo ejecutarlo o si necesitas ajustar algo, avisame! üöÄ</p>
<p>Ah, necesitas instalar Tesseract OCR en tu sistema. Como est√°s en Gentoo Linux, aqu√≠ est√°n los comandos:</p>
<h2 id="-instalaci√≥n-en-gentoo">üîß Instalaci√≥n en Gentoo</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Instalar Tesseract OCR con soporte para espa√±ol</span>
</span></span><span style="display:flex;"><span>sudo emerge -av app-text/tesseract
</span></span><span style="display:flex;"><span>sudo emerge -av app-dicts/myspell-es
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># O si prefieres los datos de idioma de tesseract:</span>
</span></span><span style="display:flex;"><span>sudo emerge -av app-text/tesseract-data-spa
</span></span><span style="display:flex;"><span>sudo emerge -av app-text/tesseract-data-eng
</span></span></code></pre></div><h2 id="-verificar-instalaci√≥n">‚úÖ Verificar instalaci√≥n</h2>
<p>Despu√©s de instalar, verifica que funcione:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>tesseract --version
</span></span><span style="display:flex;"><span>tesseract --list-langs
</span></span></code></pre></div><p>Deber√≠as ver algo como:</p>
<pre tabindex="0"><code>tesseract 5.x.x
List of available languages (2):
eng
spa
</code></pre><h2 id="-ejecutar-el-script">üöÄ Ejecutar el script</h2>
<p>Una vez instalado Tesseract, vuelve a ejecutar:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>python diccionario_pdf_to_html.py
</span></span></code></pre></div><hr>
<h2 id="-alternativa-si-hay-problemas">üîÑ Alternativa si hay problemas</h2>
<p>Si tienes problemas con emerge, puedes especificar la ruta de Tesseract manualmente en el script. Agrega esto al inicio del archivo, despu√©s de los imports:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> pytesseract
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Especifica la ruta de tesseract si no est√° en PATH</span>
</span></span><span style="display:flex;"><span>pytesseract<span style="color:#f92672">.</span>pytesseract<span style="color:#f92672">.</span>tesseract_cmd <span style="color:#f92672">=</span> <span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;/usr/bin/tesseract&#39;</span>  <span style="color:#75715e"># Ajusta esta ruta</span>
</span></span></code></pre></div><p>¬øTe funcion√≥ la instalaci√≥n? Si sigues teniendo problemas, av√≠same y te ayudo a resolverlo! üõ†Ô∏è</p>

</div>


      </div>
    </section>
  </section><script 
src="/quiz/quizdown.js">
</script>
<script 
src="/quiz/quizdownKatex.js">
</script>
<script 
src="/quiz/quizdownHighlight.js">
</script>
<script>quizdown.register(quizdownHighlight).register(quizdownKatex).init()</script> 
<footer class="footer">
  <div class="content has-text-centered">
    
    
    <p>
      
      <a class="" href="https://imlauera.github.io/index.xml" target="_blank">
        <span>
          RSS
        </span>
      </a>
      
      | <a href="https://imlauera.github.io" target="_blank">Andres Imlauer.</a> 

      
      
    </p>
    
  </div>




<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]} })
</script>
</footer>


</body>
</html>
