<!DOCTYPE html>
<html lang="es">





<head>
  <meta property="og:url" content="https://imlauera.github.io/ai_terminal/">
  <meta property="og:site_name" content="Imlauer">
  <meta property="og:title" content="AI en la terminal">
  <meta property="og:description" content="https://old.reddit.com/r/commandline/comments/1ba5k6h/claude_ai_in_terminal/?rdt=46031
https://git.blek.codes/blek/hey
yay -S hey-duck https://github.com/sigoden/aichat All in one CLI tool for 10&#43; AI platforms, including OpenAI (ChatGPT), Gemini, Claude, Mistral, LocalAI, Ollama, VertexAI, Ernie, Qianwen…
Actualmente estoy usando modelos gratuitos, no pago por ninguna API key de claude ai, ni chat gpt premium, estos son los modelos gratuitos que soporta:
[I] esotericwarfare@arch ~&gt; aichat --list-models huggingface:NousResearch/Hermes-3-Llama-3.1-8B huggingface:mistralai/Mistral-Small-Instruct-2409 huggingface:mistralai/Mistral-Nemo-Instruct-2407 [I] esotericwarfare@arch ~&gt; Options: -m, --model &lt;MODEL&gt; Select a LLM model --prompt &lt;PROMPT&gt; Use the system prompt -r, --role &lt;ROLE&gt; Select a role -s, --session [&lt;SESSION&gt;] Start or join a session --empty-session Ensure the session is empty --save-session Force the session to be saved -a, --agent &lt;AGENT&gt; Start a agent -R, --rag &lt;RAG&gt; Start a RAG --serve [&lt;ADDRESS&gt;] Serve the LLM API and WebAPP -e, --execute Execute commands in natural language -c, --code Output code only -f, --file &lt;FILE&gt; Include files with the message -S, --no-stream Turn off stream mode --dry-run Display the message without sending it --info Display information --list-models List all available chat models --list-roles List all roles --list-sessions List all sessions --list-agents List all agents --list-rags List all RAGs -h, --help Print help -V, --version Print version [I] esotericwarfare@arch ~&gt; Podemos usar el argumento --code y -S para que solo nos produzca código sin que escriba línea por línea sino que nos tire la salida de una.">
  <meta property="og:locale" content="es_es">
  <meta property="og:type" content="article">
    <meta property="article:published_time" content="2024-11-18T14:19:26-03:00">
    <meta property="article:modified_time" content="2024-11-18T14:19:26-03:00">
    <meta property="article:tag" content="Cli">

  
  <meta itemprop="name" content="AI en la terminal">
  <meta itemprop="description" content="https://old.reddit.com/r/commandline/comments/1ba5k6h/claude_ai_in_terminal/?rdt=46031
https://git.blek.codes/blek/hey
yay -S hey-duck https://github.com/sigoden/aichat All in one CLI tool for 10&#43; AI platforms, including OpenAI (ChatGPT), Gemini, Claude, Mistral, LocalAI, Ollama, VertexAI, Ernie, Qianwen…
Actualmente estoy usando modelos gratuitos, no pago por ninguna API key de claude ai, ni chat gpt premium, estos son los modelos gratuitos que soporta:
[I] esotericwarfare@arch ~&gt; aichat --list-models huggingface:NousResearch/Hermes-3-Llama-3.1-8B huggingface:mistralai/Mistral-Small-Instruct-2409 huggingface:mistralai/Mistral-Nemo-Instruct-2407 [I] esotericwarfare@arch ~&gt; Options: -m, --model &lt;MODEL&gt; Select a LLM model --prompt &lt;PROMPT&gt; Use the system prompt -r, --role &lt;ROLE&gt; Select a role -s, --session [&lt;SESSION&gt;] Start or join a session --empty-session Ensure the session is empty --save-session Force the session to be saved -a, --agent &lt;AGENT&gt; Start a agent -R, --rag &lt;RAG&gt; Start a RAG --serve [&lt;ADDRESS&gt;] Serve the LLM API and WebAPP -e, --execute Execute commands in natural language -c, --code Output code only -f, --file &lt;FILE&gt; Include files with the message -S, --no-stream Turn off stream mode --dry-run Display the message without sending it --info Display information --list-models List all available chat models --list-roles List all roles --list-sessions List all sessions --list-agents List all agents --list-rags List all RAGs -h, --help Print help -V, --version Print version [I] esotericwarfare@arch ~&gt; Podemos usar el argumento --code y -S para que solo nos produzca código sin que escriba línea por línea sino que nos tire la salida de una.">
  <meta itemprop="datePublished" content="2024-11-18T14:19:26-03:00">
  <meta itemprop="dateModified" content="2024-11-18T14:19:26-03:00">
  <meta itemprop="wordCount" content="260">
  <meta itemprop="keywords" content="Cli">
  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="AI en la terminal">
  <meta name="twitter:description" content="https://old.reddit.com/r/commandline/comments/1ba5k6h/claude_ai_in_terminal/?rdt=46031
https://git.blek.codes/blek/hey
yay -S hey-duck https://github.com/sigoden/aichat All in one CLI tool for 10&#43; AI platforms, including OpenAI (ChatGPT), Gemini, Claude, Mistral, LocalAI, Ollama, VertexAI, Ernie, Qianwen…
Actualmente estoy usando modelos gratuitos, no pago por ninguna API key de claude ai, ni chat gpt premium, estos son los modelos gratuitos que soporta:
[I] esotericwarfare@arch ~&gt; aichat --list-models huggingface:NousResearch/Hermes-3-Llama-3.1-8B huggingface:mistralai/Mistral-Small-Instruct-2409 huggingface:mistralai/Mistral-Nemo-Instruct-2407 [I] esotericwarfare@arch ~&gt; Options: -m, --model &lt;MODEL&gt; Select a LLM model --prompt &lt;PROMPT&gt; Use the system prompt -r, --role &lt;ROLE&gt; Select a role -s, --session [&lt;SESSION&gt;] Start or join a session --empty-session Ensure the session is empty --save-session Force the session to be saved -a, --agent &lt;AGENT&gt; Start a agent -R, --rag &lt;RAG&gt; Start a RAG --serve [&lt;ADDRESS&gt;] Serve the LLM API and WebAPP -e, --execute Execute commands in natural language -c, --code Output code only -f, --file &lt;FILE&gt; Include files with the message -S, --no-stream Turn off stream mode --dry-run Display the message without sending it --info Display information --list-models List all available chat models --list-roles List all roles --list-sessions List all sessions --list-agents List all agents --list-rags List all RAGs -h, --help Print help -V, --version Print version [I] esotericwarfare@arch ~&gt; Podemos usar el argumento --code y -S para que solo nos produzca código sin que escriba línea por línea sino que nos tire la salida de una.">

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>
    
    AI en la terminal
    
  </title>
  <link rel="stylesheet" href='https://imlauera.github.io/css/site.min.css'>
  <link rel="canonical" href="https://imlauera.github.io/ai_terminal/">
  <link rel="alternate" type="application/rss&#43;xml" href="https://imlauera.github.io/index.xml" title="Imlauer">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="referrer" content="no-referrer">
  <meta name="author" content="Imlauer.">
  <meta name="description" content="https://old.reddit.com/r/commandline/comments/1ba5k6h/claude_ai_in_terminal/?rdt=46031
https://git.blek.codes/blek/hey
yay -S hey-duck
https://github.com/sigoden/aichat All in one CLI tool for 10&#43; AI platforms, including OpenAI (ChatGPT), Gemini, Claude, Mistral, LocalAI, Ollama, VertexAI, Ernie, Qianwen&hellip;
Actualmente estoy usando modelos gratuitos, no pago por ninguna API key de claude ai, ni chat gpt premium, estos son los modelos gratuitos que soporta:
[I] esotericwarfare@arch ~&gt; aichat --list-models
huggingface:NousResearch/Hermes-3-Llama-3.1-8B
huggingface:mistralai/Mistral-Small-Instruct-2409
huggingface:mistralai/Mistral-Nemo-Instruct-2407
[I] esotericwarfare@arch ~&gt;

Options:
  -m, --model &lt;MODEL&gt;        Select a LLM model
      --prompt &lt;PROMPT&gt;      Use the system prompt
  -r, --role &lt;ROLE&gt;          Select a role
  -s, --session [&lt;SESSION&gt;]  Start or join a session
      --empty-session        Ensure the session is empty
      --save-session         Force the session to be saved
  -a, --agent &lt;AGENT&gt;        Start a agent
  -R, --rag &lt;RAG&gt;            Start a RAG
      --serve [&lt;ADDRESS&gt;]    Serve the LLM API and WebAPP
  -e, --execute              Execute commands in natural language
  -c, --code                 Output code only
  -f, --file &lt;FILE&gt;          Include files with the message
  -S, --no-stream            Turn off stream mode
      --dry-run              Display the message without sending it
      --info                 Display information
      --list-models          List all available chat models
      --list-roles           List all roles
      --list-sessions        List all sessions
      --list-agents          List all agents
      --list-rags            List all RAGs
  -h, --help                 Print help
  -V, --version              Print version
[I] esotericwarfare@arch ~&gt;
Podemos usar el argumento --code y -S para que solo nos produzca código sin que escriba línea por línea sino que nos tire la salida de una.">
</head>
<body><nav class="navbar is-transparent " role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a class="navbar-item" href="https://imlauera.github.io/">
      <figure class="image">
        <img alt="" class="is-rounded" src="/img/memememe.jpg">
      </figure>
    </a>
    <a class="navbar-item" href="https://imlauera.github.io/">
      Imlauer
    </a>
    <a class="navbar-item" href="/acerca/">
      Acerca de Mi
    </a>
  </div>
  
  
</nav>

  <section>
    <section class='hero is-small is-link is-fullwidth'>
      <div class="hero-body">
<div class="container">
  <h1 class="title">
    AI en la terminal
  </h1>
  <h2 class="subtitle">
    <time datetime='2024-11-18T14:19:26-03:00'>
      November 18, 2024
    </time>
    
    <br>
    
    
    
    <a class="tag is-info" href="https://imlauera.github.io/tags/cli/">Cli</a>
    
    
    
  </h2>
</div>

      </div>
    </section>
    <section class="section">
      <div class="container">
<div class="content is-medium">
  <p><a href="https://old.reddit.com/r/commandline/comments/1ba5k6h/claude_ai_in_terminal/?rdt=46031">https://old.reddit.com/r/commandline/comments/1ba5k6h/claude_ai_in_terminal/?rdt=46031</a></p>
<p><a href="https://git.blek.codes/blek/hey">https://git.blek.codes/blek/hey</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yay -S hey-duck
</span></span></code></pre></div><p><a href="https://github.com/sigoden/aichat">https://github.com/sigoden/aichat</a> All in one CLI tool for 10+ AI platforms, including OpenAI (ChatGPT), Gemini, Claude, Mistral, LocalAI, Ollama, VertexAI, Ernie, Qianwen&hellip;</p>
<p>Actualmente estoy usando modelos gratuitos, no pago por ninguna API key de claude ai, ni chat gpt premium, estos son los modelos gratuitos que soporta:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>I<span style="color:#f92672">]</span> esotericwarfare@arch ~&gt; aichat --list-models
</span></span><span style="display:flex;"><span>huggingface:NousResearch/Hermes-3-Llama-3.1-8B
</span></span><span style="display:flex;"><span>huggingface:mistralai/Mistral-Small-Instruct-2409
</span></span><span style="display:flex;"><span>huggingface:mistralai/Mistral-Nemo-Instruct-2407
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>I<span style="color:#f92672">]</span> esotericwarfare@arch ~&gt;
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Options:
</span></span><span style="display:flex;"><span>  -m, --model &lt;MODEL&gt;        Select a LLM model
</span></span><span style="display:flex;"><span>      --prompt &lt;PROMPT&gt;      Use the system prompt
</span></span><span style="display:flex;"><span>  -r, --role &lt;ROLE&gt;          Select a role
</span></span><span style="display:flex;"><span>  -s, --session <span style="color:#f92672">[</span>&lt;SESSION&gt;<span style="color:#f92672">]</span>  Start or join a session
</span></span><span style="display:flex;"><span>      --empty-session        Ensure the session is empty
</span></span><span style="display:flex;"><span>      --save-session         Force the session to be saved
</span></span><span style="display:flex;"><span>  -a, --agent &lt;AGENT&gt;        Start a agent
</span></span><span style="display:flex;"><span>  -R, --rag &lt;RAG&gt;            Start a RAG
</span></span><span style="display:flex;"><span>      --serve <span style="color:#f92672">[</span>&lt;ADDRESS&gt;<span style="color:#f92672">]</span>    Serve the LLM API and WebAPP
</span></span><span style="display:flex;"><span>  -e, --execute              Execute commands in natural language
</span></span><span style="display:flex;"><span>  -c, --code                 Output code only
</span></span><span style="display:flex;"><span>  -f, --file &lt;FILE&gt;          Include files with the message
</span></span><span style="display:flex;"><span>  -S, --no-stream            Turn off stream mode
</span></span><span style="display:flex;"><span>      --dry-run              Display the message without sending it
</span></span><span style="display:flex;"><span>      --info                 Display information
</span></span><span style="display:flex;"><span>      --list-models          List all available chat models
</span></span><span style="display:flex;"><span>      --list-roles           List all roles
</span></span><span style="display:flex;"><span>      --list-sessions        List all sessions
</span></span><span style="display:flex;"><span>      --list-agents          List all agents
</span></span><span style="display:flex;"><span>      --list-rags            List all RAGs
</span></span><span style="display:flex;"><span>  -h, --help                 Print help
</span></span><span style="display:flex;"><span>  -V, --version              Print version
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>I<span style="color:#f92672">]</span> esotericwarfare@arch ~&gt;
</span></span></code></pre></div><p>Podemos usar el argumento <code>--code</code> y <code>-S</code> para que solo nos produzca código sin que escriba línea por línea sino que nos tire la salida de una.</p>
<p>Ejemplo de uso:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>aichat -S --code <span style="color:#e6db74">&#34;programá un juego multiple choice en C&#34;</span>
</span></span></code></pre></div><p>Y pueden usar también tgpt: <code>yay -S tgpt</code></p>
<p>Ejemplos de uso:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>aichat
</span></span><span style="display:flex;"><span>tgpt -m 
</span></span></code></pre></div><p>La AI es buena para construir aplicaciones en python.</p>
<p>Que te diviertas, hasta luego.</p>

</div>


      </div>
    </section>
  </section><script 
src="/quiz/quizdown.js">
</script>
<script 
src="/quiz/quizdownKatex.js">
</script>
<script 
src="/quiz/quizdownHighlight.js">
</script>
<script>quizdown.register(quizdownHighlight).register(quizdownKatex).init()</script> 
<footer class="footer">
  <div class="content has-text-centered">
    
    
    <p>
      
      <a class="" href="https://imlauera.github.io/index.xml" target="_blank">
        <span>
          RSS
        </span>
      </a>
      
      | <a href="https://imlauera.github.io" target="_blank">Andres Imlauer.</a> 

      
      
    </p>
    
  </div>




<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]} })
</script>
</footer>


</body>
</html>
