<!DOCTYPE html>
<html lang="es">





<head>
  <meta property="og:url" content="https://imlauera.github.io/kiwix_llm/">
  <meta property="og:site_name" content="Imlauer">
  <meta property="og:title" content="Ejecutar un LLM con archivos Kiwix offline gratis sin ChatGPT.">
  <meta property="og:description" content="‚úÖ What to do after running the script Put your .zim files somewhere, for example: ~/zimfiles/ Or set:
export KIWIX_HOME=~/zimfiles Run a query: llm -m llama3.2 --tool kiwix_search_and_collect &#34;How do I install Gentoo?&#34; The LLM will:
Search inside your ZIM file Extract relevant article content Use Llama 3.2 locally to answer No API keys needed. No LangChain. No internet.
Completely offline.
üî• Want an even better version? I can also generate:">
  <meta property="og:locale" content="es_es">
  <meta property="og:type" content="article">
    <meta property="article:published_time" content="2025-11-22T19:44:13-03:00">
    <meta property="article:modified_time" content="2025-11-22T19:44:13-03:00">

  
  <meta itemprop="name" content="Ejecutar un LLM con archivos Kiwix offline gratis sin ChatGPT.">
  <meta itemprop="description" content="‚úÖ What to do after running the script Put your .zim files somewhere, for example: ~/zimfiles/ Or set:
export KIWIX_HOME=~/zimfiles Run a query: llm -m llama3.2 --tool kiwix_search_and_collect &#34;How do I install Gentoo?&#34; The LLM will:
Search inside your ZIM file Extract relevant article content Use Llama 3.2 locally to answer No API keys needed. No LangChain. No internet.
Completely offline.
üî• Want an even better version? I can also generate:">
  <meta itemprop="datePublished" content="2025-11-22T19:44:13-03:00">
  <meta itemprop="dateModified" content="2025-11-22T19:44:13-03:00">
  <meta itemprop="wordCount" content="593">
  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Ejecutar un LLM con archivos Kiwix offline gratis sin ChatGPT.">
  <meta name="twitter:description" content="‚úÖ What to do after running the script Put your .zim files somewhere, for example: ~/zimfiles/ Or set:
export KIWIX_HOME=~/zimfiles Run a query: llm -m llama3.2 --tool kiwix_search_and_collect &#34;How do I install Gentoo?&#34; The LLM will:
Search inside your ZIM file Extract relevant article content Use Llama 3.2 locally to answer No API keys needed. No LangChain. No internet.
Completely offline.
üî• Want an even better version? I can also generate:">

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>
    
    Ejecutar un LLM con archivos Kiwix offline gratis sin ChatGPT.
    
  </title>
  <link rel="stylesheet" href='https://imlauera.github.io/css/site.min.css'>
  <link rel="canonical" href="https://imlauera.github.io/kiwix_llm/">
  <link rel="alternate" type="application/rss&#43;xml" href="https://imlauera.github.io/index.xml" title="Imlauer">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="referrer" content="no-referrer">
  <meta name="author" content="Imlauer.">
  <meta name="description" content="‚úÖ What to do after running the script

Put your .zim files somewhere, for example:

~/zimfiles/
Or set:
export KIWIX_HOME=~/zimfiles

Run a query:

llm -m llama3.2 --tool kiwix_search_and_collect &#34;How do I install Gentoo?&#34;
The LLM will:

Search inside your ZIM file
Extract relevant article content
Use Llama 3.2 locally to answer

No API keys needed.
No LangChain.
No internet.
Completely offline.

üî• Want an even better version?
I can also generate:">
</head>
<body><nav class="navbar is-transparent " role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a class="navbar-item" href="https://imlauera.github.io/">
      <figure class="image">
        <img alt="" class="is-rounded" src="/img/memememe.jpg">
      </figure>
    </a>
    <a class="navbar-item" href="https://imlauera.github.io/">
      Imlauer
    </a>
    <a class="navbar-item" href="/acerca/">
      Acerca de Mi
    </a>
  </div>
  
  
</nav>

  <section>
    <section class='hero is-small is-link is-fullwidth'>
      <div class="hero-body">
<div class="container">
  <h1 class="title">
    Ejecutar un LLM con archivos Kiwix offline gratis sin ChatGPT.
  </h1>
  <h2 class="subtitle">
    <time datetime='2025-11-22T19:44:13-03:00'>
      November 22, 2025
    </time>
    
  </h2>
</div>

      </div>
    </section>
    <section class="section">
      <div class="container">
<div class="content is-medium">
  <h1 id="-what-to-do-after-running-the-script">‚úÖ What to do after running the script</h1>
<ol>
<li>Put your <code>.zim</code> files somewhere, for example:</li>
</ol>
<pre tabindex="0"><code>~/zimfiles/
</code></pre><p>Or set:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export KIWIX_HOME<span style="color:#f92672">=</span>~/zimfiles
</span></span></code></pre></div><ol start="2">
<li>Run a query:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>llm -m llama3.2 --tool kiwix_search_and_collect <span style="color:#e6db74">&#34;How do I install Gentoo?&#34;</span>
</span></span></code></pre></div><p>The LLM will:</p>
<ul>
<li>Search inside your ZIM file</li>
<li>Extract relevant article content</li>
<li>Use <strong>Llama 3.2 locally</strong> to answer</li>
</ul>
<p>No API keys needed.
No LangChain.
No internet.</p>
<p>Completely <strong>offline</strong>.</p>
<hr>
<h1 id="-want-an-even-better-version">üî• Want an even better version?</h1>
<p>I can also generate:</p>
<ul>
<li>A TUI (terminal UI) browser</li>
<li>A web UI</li>
<li>A local RAG server</li>
<li>A fully packaged Arch <code>PKGBUILD</code></li>
</ul>
<p>Just tell me what you want.</p>
<p>You want to <strong>know how to use <code>llm-tools-kiwix</code></strong>, right? I‚Äôll break it down step by step so you can get a fully working setup <strong>without OpenAI</strong>, using a free local model.</p>
<hr>
<h1 id="1-install-llm-cli">1Ô∏è‚É£ Install <code>llm</code> CLI</h1>
<p>If you haven‚Äôt already:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>python -m venv llm-tools-kiwix
</span></span><span style="display:flex;"><span>pip install llm
</span></span></code></pre></div><p>or follow their <a href="https://github.com/rschmukler/llm">official instructions</a>.</p>
<p>Check it works:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>llm --version
</span></span></code></pre></div><hr>
<h1 id="2-install-llm-tools-kiwix">2Ô∏è‚É£ Install <code>llm-tools-kiwix</code></h1>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>llm install llm-tools-kiwix
</span></span></code></pre></div><p>Check installed tools:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>llm tools list
</span></span></code></pre></div><p>You should see:</p>
<ul>
<li><code>kiwix_search</code></li>
<li><code>kiwix_search_and_collect</code></li>
<li><code>kiwix_read</code></li>
</ul>
<hr>
<h1 id="3-install-a-free-local-llm-ollama-recommended">3Ô∏è‚É£ Install a <strong>free local LLM</strong> (Ollama recommended)</h1>
<h3 id="step-a--install-ollama">Step A ‚Äî Install Ollama</h3>
<p>Follow instructions for your OS: <a href="https://ollama.com/download">https://ollama.com/download</a></p>
<h3 id="step-b--pull-a-free-model">Step B ‚Äî Pull a free model</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ollama pull llama3.2 <span style="color:#f92672">(</span><span style="color:#ae81ff">2</span> GB<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>ollama pull deepseek-r1 <span style="color:#f92672">(</span><span style="color:#ae81ff">5</span> GB<span style="color:#f92672">)</span>
</span></span></code></pre></div><h3 id="step-c--install-llm-ollama-plugin">Step C ‚Äî Install <code>llm-ollama</code> plugin</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>llm install llm-ollama
</span></span></code></pre></div><h3 id="step-d--set-default-model">Step D ‚Äî Set default model</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>llm models set-default ollama/llama3.2
</span></span><span style="display:flex;"><span>llm -m llama3.2
</span></span></code></pre></div><p>Now <code>llm</code> will use your <strong>local LLM</strong> instead of OpenAI.</p>
<hr>
<h1 id="4-use-llm-tools-kiwix">4Ô∏è‚É£ Use <code>llm-tools-kiwix</code></h1>
<p>Make sure you have <strong>at least one ZIM file</strong> (e.g., Wikipedia):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>llm --tool kiwix_search <span style="color:#e6db74">&#34;Gentoo installation&#34;</span>
</span></span></code></pre></div><p>Or to <strong>retrieve and read articles</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>llm --tool kiwix_search_and_collect <span style="color:#e6db74">&#34;How do I install Gentoo&#34;</span>
</span></span></code></pre></div><p>You can also directly read a specific article:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>llm --tool kiwix_read <span style="color:#e6db74">&#34;Gentoo/Installation&#34;</span>
</span></span></code></pre></div><hr>
<h1 id="5-notes--tips">5Ô∏è‚É£ Notes / Tips</h1>
<ul>
<li>By default, <code>kiwix_search</code> searches <strong>titles only</strong>.</li>
<li><code>kiwix_search_and_collect</code> fetches the <strong>full article text</strong>.</li>
<li>You <strong>don‚Äôt need any API key</strong> if you‚Äôre using Ollama.</li>
</ul>
<hr>
<p>If you want, I can make a <strong>single ‚Äúcopy-paste‚Äù script</strong> that:</p>
<ol>
<li>Installs <code>llm</code></li>
<li>Installs <code>llm-tools-kiwix</code></li>
<li>Installs Ollama and pulls a free model</li>
<li>Lets you query a ZIM file immediately</li>
</ol>
<p>This way, you can run <strong>one command and have it working fully offline</strong>.</p>
<p>Do you want me to do that?</p>
<hr>
<p>Below is a <strong>single copy-paste script</strong> that sets up everything you need:</p>
<p>‚úÖ <code>llm</code> CLI
‚úÖ <code>llm-tools-kiwix</code>
‚úÖ <code>llm-ollama</code>
‚úÖ Ollama + free model
‚úÖ Fully offline ZIM search + LLM answering</p>
<p>Works on <strong>Arch Linux</strong> (since you‚Äôre on Arch).</p>
<hr>
<h1 id="-one-command-full-setup-script-arch-linux">üöÄ <strong>ONE-COMMAND FULL SETUP SCRIPT (ARCH LINUX)</strong></h1>
<p>Copy this entire block and save it as <code>setup_kiwix_llm.sh</code>, then run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>bash setup_kiwix_llm.sh
</span></span></code></pre></div><hr>
<h3 id="-setup_"><strong>üìå setup_kiwix_llm.sh</strong></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">#!/usr/bin/env bash
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>set -e
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;=== Updating system ===&#34;</span>
</span></span><span style="display:flex;"><span>sudo pacman -Sy --noconfirm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;=== Installing Python + pip ===&#34;</span>
</span></span><span style="display:flex;"><span>sudo pacman -S --noconfirm python python-pip
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;=== Installing llm CLI ===&#34;</span>
</span></span><span style="display:flex;"><span>pip install --upgrade llm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;=== Installing llm-tools-kiwix ===&#34;</span>
</span></span><span style="display:flex;"><span>llm install llm-tools-kiwix
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;=== Installing llm-ollama backend ===&#34;</span>
</span></span><span style="display:flex;"><span>llm install llm-ollama
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;=== Installing Ollama ===&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Official Arch package</span>
</span></span><span style="display:flex;"><span>sudo pacman -S --noconfirm ollama
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;=== Starting Ollama service ===&#34;</span>
</span></span><span style="display:flex;"><span>sudo systemctl enable --now ollama.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;=== Pulling free local LLM (Llama 3.2) ===&#34;</span>
</span></span><span style="display:flex;"><span>ollama pull llama3.2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;=== Setting Llama 3.2 as default llm model ===&#34;</span>
</span></span><span style="display:flex;"><span>llm models set-default ollama/llama3.2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;======================================================&#34;</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34; Setup complete!&#34;</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34; You can now run offline ZIM + LLM commands, for example:&#34;</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;   llm --tool kiwix_search &#34;Gentoo installation&#34;&#39;</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;   llm --tool kiwix_search_and_collect &#34;How do I install Gentoo?&#34;&#39;</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;Place your ZIM files in the current folder or set KIWIX_HOME.&#34;</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;======================================================&#34;</span>
</span></span></code></pre></div><hr>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span> llm -m llama3.2 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>                                  --tool kiwix_search <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>                                  --zim zim-llm/zim_library/gentoo_en_all_maxi_2021-03.zim <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>                                  <span style="color:#e6db74">&#34;How do I install Gentoo?&#34;</span>
</span></span></code></pre></div><p><img src="https://miinstagram.github.io/random/IMG_20251126_025223728.jpg" alt=""></p>

</div>


      </div>
    </section>
  </section><script 
src="/quiz/quizdown.js">
</script>
<script 
src="/quiz/quizdownKatex.js">
</script>
<script 
src="/quiz/quizdownHighlight.js">
</script>
<script>quizdown.register(quizdownHighlight).register(quizdownKatex).init()</script> 
<footer class="footer">
  <div class="content has-text-centered">
    
    
    <p>
      
      <a class="" href="https://imlauera.github.io/index.xml" target="_blank">
        <span>
          RSS
        </span>
      </a>
      
      | <a href="https://imlauera.github.io" target="_blank">Andres Imlauer.</a> 

      
      
    </p>
    
  </div>




<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]} })
</script>
</footer>


</body>
</html>
