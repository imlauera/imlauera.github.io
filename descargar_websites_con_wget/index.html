<!DOCTYPE html>
<html lang="es">





<head>
  <meta property="og:url" content="https://imlauera.github.io/descargar_websites_con_wget/">
  <meta property="og:site_name" content="Imlauer">
  <meta property="og:title" content="Descargar paginas enteras con Wget">
  <meta property="og:description" content="Nunca mires nada online. Siempre descargatelo y si es mejor usa Tor.
Puedo explicarte **c√≥mo usar `wget` para descargar un sitio MediaWiki**, pero **sin apoyar ni promover el contenido** del sitio que mencionas. Te doy √∫nicamente **instrucciones t√©cnicas y neutrales**, v√°lidas para *cualquier* wiki. --- # ‚úÖ Descargar una wiki con `wget` (m√©todo general) `wget` puede hacer una ‚Äúcopia navegable‚Äù del sitio, pero **NO** obtendr√°s: * el historial de ediciones * la base de datos real * algunos recursos protegidos Aun as√≠, sirve para copia *offline de lectura*. --- # üìå **Comando b√°sico recomendado** ```bash wget \ --mirror \ --convert-links \ --adjust-extension \ --page-requisites \ --no-parent \ https://incels.wiki/ üîç ¬øQu√© hace cada opci√≥n? Opci√≥n Funci√≥n --mirror Activa recursividad, respeta tiempos, etc. (equivalente a -r -N -l inf --no-remove-listing) --convert-links Convierte los enlaces para que funcionen offline --adjust-extension Asigna extensiones correctas (.html) --page-requisites Descarga CSS, im√°genes y JS necesarios --no-parent Evita subir a directorios superiores URL P√°gina inicial del sitio a copiar üìå Aumentar profundidad (descargar m√°s p√°ginas) MediaWiki usa muchos enlaces internos; a veces conviene a√±adir recursividad expl√≠cita:">
  <meta property="og:locale" content="es_es">
  <meta property="og:type" content="article">
    <meta property="article:published_time" content="2025-11-23T04:34:21-03:00">
    <meta property="article:modified_time" content="2025-11-23T04:34:21-03:00">
    <meta property="article:tag" content="Cli">

  
  <meta itemprop="name" content="Descargar paginas enteras con Wget">
  <meta itemprop="description" content="Nunca mires nada online. Siempre descargatelo y si es mejor usa Tor.
Puedo explicarte **c√≥mo usar `wget` para descargar un sitio MediaWiki**, pero **sin apoyar ni promover el contenido** del sitio que mencionas. Te doy √∫nicamente **instrucciones t√©cnicas y neutrales**, v√°lidas para *cualquier* wiki. --- # ‚úÖ Descargar una wiki con `wget` (m√©todo general) `wget` puede hacer una ‚Äúcopia navegable‚Äù del sitio, pero **NO** obtendr√°s: * el historial de ediciones * la base de datos real * algunos recursos protegidos Aun as√≠, sirve para copia *offline de lectura*. --- # üìå **Comando b√°sico recomendado** ```bash wget \ --mirror \ --convert-links \ --adjust-extension \ --page-requisites \ --no-parent \ https://incels.wiki/ üîç ¬øQu√© hace cada opci√≥n? Opci√≥n Funci√≥n --mirror Activa recursividad, respeta tiempos, etc. (equivalente a -r -N -l inf --no-remove-listing) --convert-links Convierte los enlaces para que funcionen offline --adjust-extension Asigna extensiones correctas (.html) --page-requisites Descarga CSS, im√°genes y JS necesarios --no-parent Evita subir a directorios superiores URL P√°gina inicial del sitio a copiar üìå Aumentar profundidad (descargar m√°s p√°ginas) MediaWiki usa muchos enlaces internos; a veces conviene a√±adir recursividad expl√≠cita:">
  <meta itemprop="datePublished" content="2025-11-23T04:34:21-03:00">
  <meta itemprop="dateModified" content="2025-11-23T04:34:21-03:00">
  <meta itemprop="wordCount" content="712">
  <meta itemprop="keywords" content="Cli">
  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Descargar paginas enteras con Wget">
  <meta name="twitter:description" content="Nunca mires nada online. Siempre descargatelo y si es mejor usa Tor.
Puedo explicarte **c√≥mo usar `wget` para descargar un sitio MediaWiki**, pero **sin apoyar ni promover el contenido** del sitio que mencionas. Te doy √∫nicamente **instrucciones t√©cnicas y neutrales**, v√°lidas para *cualquier* wiki. --- # ‚úÖ Descargar una wiki con `wget` (m√©todo general) `wget` puede hacer una ‚Äúcopia navegable‚Äù del sitio, pero **NO** obtendr√°s: * el historial de ediciones * la base de datos real * algunos recursos protegidos Aun as√≠, sirve para copia *offline de lectura*. --- # üìå **Comando b√°sico recomendado** ```bash wget \ --mirror \ --convert-links \ --adjust-extension \ --page-requisites \ --no-parent \ https://incels.wiki/ üîç ¬øQu√© hace cada opci√≥n? Opci√≥n Funci√≥n --mirror Activa recursividad, respeta tiempos, etc. (equivalente a -r -N -l inf --no-remove-listing) --convert-links Convierte los enlaces para que funcionen offline --adjust-extension Asigna extensiones correctas (.html) --page-requisites Descarga CSS, im√°genes y JS necesarios --no-parent Evita subir a directorios superiores URL P√°gina inicial del sitio a copiar üìå Aumentar profundidad (descargar m√°s p√°ginas) MediaWiki usa muchos enlaces internos; a veces conviene a√±adir recursividad expl√≠cita:">

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>
    
    Descargar paginas enteras con Wget
    
  </title>
  <link rel="stylesheet" href='https://imlauera.github.io/css/site.min.css'>
  <link rel="canonical" href="https://imlauera.github.io/descargar_websites_con_wget/">
  <link rel="alternate" type="application/rss&#43;xml" href="https://imlauera.github.io/index.xml" title="Imlauer">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="referrer" content="no-referrer">
  <meta name="author" content="Imlauer.">
  <meta name="description" content="Nunca mires nada online. Siempre descargatelo y si es mejor usa Tor.
Puedo explicarte **c√≥mo usar `wget` para descargar un sitio MediaWiki**, pero **sin apoyar ni promover el contenido** del sitio que mencionas.
Te doy √∫nicamente **instrucciones t√©cnicas y neutrales**, v√°lidas para *cualquier* wiki.

---

# ‚úÖ Descargar una wiki con `wget` (m√©todo general)

`wget` puede hacer una ‚Äúcopia navegable‚Äù del sitio, pero **NO** obtendr√°s:

* el historial de ediciones
* la base de datos real
* algunos recursos protegidos

Aun as√≠, sirve para copia *offline de lectura*.

---

# üìå **Comando b√°sico recomendado**

```bash
wget \
  --mirror \
  --convert-links \
  --adjust-extension \
  --page-requisites \
  --no-parent \
  https://incels.wiki/
üîç ¬øQu√© hace cada opci√≥n?

  
      
          Opci√≥n
          Funci√≥n
      
  
  
      
          --mirror
          Activa recursividad, respeta tiempos, etc. (equivalente a -r -N -l inf --no-remove-listing)
      
      
          --convert-links
          Convierte los enlaces para que funcionen offline
      
      
          --adjust-extension
          Asigna extensiones correctas (.html)
      
      
          --page-requisites
          Descarga CSS, im√°genes y JS necesarios
      
      
          --no-parent
          Evita subir a directorios superiores
      
      
          URL
          P√°gina inicial del sitio a copiar
      
  


üìå Aumentar profundidad (descargar m√°s p√°ginas)
MediaWiki usa muchos enlaces internos; a veces conviene a√±adir recursividad expl√≠cita:">
</head>
<body><nav class="navbar is-transparent " role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a class="navbar-item" href="https://imlauera.github.io/">
      <figure class="image">
        <img alt="" class="is-rounded" src="/img/memememe.jpg">
      </figure>
    </a>
    <a class="navbar-item" href="https://imlauera.github.io/">
      Imlauer
    </a>
    <a class="navbar-item" href="/acerca/">
      Acerca de Mi
    </a>
  </div>
  
  
</nav>

  <section>
    <section class='hero is-small is-link is-fullwidth'>
      <div class="hero-body">
<div class="container">
  <h1 class="title">
    Descargar paginas enteras con Wget
  </h1>
  <h2 class="subtitle">
    <time datetime='2025-11-23T04:34:21-03:00'>
      November 23, 2025
    </time>
    
    <br>
    
    
    
    <a class="tag is-info" href="https://imlauera.github.io/tags/cli/">Cli</a>
    
    
    
  </h2>
</div>

      </div>
    </section>
    <section class="section">
      <div class="container">
<div class="content is-medium">
  <p>Nunca mires nada online. Siempre descargatelo y si es mejor usa Tor.</p>
<pre tabindex="0"><code>Puedo explicarte **c√≥mo usar `wget` para descargar un sitio MediaWiki**, pero **sin apoyar ni promover el contenido** del sitio que mencionas.
Te doy √∫nicamente **instrucciones t√©cnicas y neutrales**, v√°lidas para *cualquier* wiki.

---

# ‚úÖ Descargar una wiki con `wget` (m√©todo general)

`wget` puede hacer una ‚Äúcopia navegable‚Äù del sitio, pero **NO** obtendr√°s:

* el historial de ediciones
* la base de datos real
* algunos recursos protegidos

Aun as√≠, sirve para copia *offline de lectura*.

---

# üìå **Comando b√°sico recomendado**

```bash
wget \
  --mirror \
  --convert-links \
  --adjust-extension \
  --page-requisites \
  --no-parent \
  https://incels.wiki/
</code></pre><h3 id="-qu√©-hace-cada-opci√≥n">üîç ¬øQu√© hace cada opci√≥n?</h3>
<table>
  <thead>
      <tr>
          <th>Opci√≥n</th>
          <th>Funci√≥n</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>--mirror</code></td>
          <td>Activa recursividad, respeta tiempos, etc. (equivalente a <code>-r -N -l inf --no-remove-listing</code>)</td>
      </tr>
      <tr>
          <td><code>--convert-links</code></td>
          <td>Convierte los enlaces para que funcionen offline</td>
      </tr>
      <tr>
          <td><code>--adjust-extension</code></td>
          <td>Asigna extensiones correctas (.html)</td>
      </tr>
      <tr>
          <td><code>--page-requisites</code></td>
          <td>Descarga CSS, im√°genes y JS necesarios</td>
      </tr>
      <tr>
          <td><code>--no-parent</code></td>
          <td>Evita subir a directorios superiores</td>
      </tr>
      <tr>
          <td>URL</td>
          <td>P√°gina inicial del sitio a copiar</td>
      </tr>
  </tbody>
</table>
<hr>
<h1 id="-aumentar-profundidad-descargar-m√°s-p√°ginas">üìå Aumentar profundidad (descargar m√°s p√°ginas)</h1>
<p>MediaWiki usa muchos enlaces internos; a veces conviene a√±adir recursividad expl√≠cita:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -r -l <span style="color:#ae81ff">5</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --convert-links <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --page-requisites <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --adjust-extension <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --no-parent <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  https://incels.wiki/
</span></span></code></pre></div><p><code>-l 5</code> significa ‚Äúcinco niveles de recursi√≥n‚Äù. Puedes aumentar, pero es m√°s lento.</p>
<hr>
<h1 id="-si-el-sitio-bloquea-wget">üìå Si el sitio bloquea <code>wget</code></h1>
<p>Algunas wikis bloquean agentes autom√°ticos. Puedes intentar:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --mirror <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --convert-links <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --page-requisites <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --adjust-extension <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --no-parent <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user-agent<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Mozilla/5.0&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  https://incels.wiki/
</span></span></code></pre></div><hr>
<h1 id="-advertencias-importantes">‚ö†Ô∏è Advertencias importantes</h1>
<ul>
<li><strong>Respeta la licencia del contenido</strong> (muchas wikis usan CC-BY-SA).</li>
<li><strong>No generes carga excesiva</strong>: usa wget con moderaci√≥n.</li>
<li><strong>No uses las copias para hospedar, republicar ni promover contenido da√±ino</strong>.</li>
</ul>
<hr>
<h1 id="-quieres-algo-m√°s-completo">üìå ¬øQuieres algo m√°s completo?</h1>
<p>Si necesitas una forma <strong>mejor que wget</strong> (por ejemplo, un dump XML de toda la wiki), puedo explicarte c√≥mo usar <strong>WikiTeam3</strong>, que est√° hecho espec√≠ficamente para descargar wikis completas.</p>
<p>¬øQuieres usar <code>wget</code> solamente o prefieres una copia tipo ‚Äúdump‚Äù como las de MediaWiki?</p>
<hr>
<p>Muy buena pregunta. Si quer√©s un <strong>dump XML</strong> de incels.wiki (o ‚Äúincel.wiki‚Äù), hay algunas limitaciones importantes, m√°s que nada si no sos administrador del sitio. No encontr√© evidencia p√∫blica de que incels.wiki tenga dumps oficiales disponibles para descarga libre, por lo que las opciones son m√°s bien ‚Äúhacer tu propio dump‚Äù mediante herramientas o pedirlo a los due√±os del wiki.</p>
<p>Te explico las opciones + c√≥mo hacerlo:</p>
<hr>
<h2 id="-opciones-para-hacer-un-dump-xml">‚öôÔ∏è Opciones para hacer un dump XML</h2>
<ol>
<li>
<p><strong>Usar WikiTeam3</strong></p>
<ul>
<li>
<p>WikiTeam tiene una herramienta llamada <strong>WikiTeam3 / MediaWiki Dump Generator</strong>, que permite generar un dump XML de la wiki, usando la API o el scraping. (<a href="https://wiki.archiveteam.org/index.php/WikiTeam?utm_source=chatgpt.com" title="WikiTeam - Archiveteam">Archive Team</a>)</p>
</li>
<li>
<p>Esta herramienta puede guardar <strong>el historial completo</strong> o solo las revisiones m√°s recientes. (<a href="https://wiki.archiveteam.org/index.php/WikiTeam?utm_source=chatgpt.com" title="WikiTeam - Archiveteam">Archive Team</a>)</p>
</li>
<li>
<p>Ejemplo de comando (suponiendo que us√°s Python 3):</p>
<pre tabindex="0"><code>wikiteam3dumpgenerator https://incels.wiki --xml --xmlrevisions
</code></pre></li>
<li>
<p>Esto va a hacer llamadas a la API de MediaWiki para bajar los art√≠culos y sus revisiones (no es exactamente igual a usar <code>dumpBackup.php</code>, pero es lo m√°s cercano si no ten√©s acceso al servidor).</p>
</li>
</ul>
</li>
<li>
<p><strong>Usar <code>Special:Export</code> de MediaWiki</strong></p>
<ul>
<li>Si acced√©s a la wiki como usuario, pod√©s ir a <code>Special:Export</code>:
<code>https://incels.wiki/index.php?title=Special:Export</code></li>
<li>Ah√≠ pod√©s poner los nombres de las p√°ginas que quer√©s exportar y bajar un XML con su contenido.</li>
<li>Limitaci√≥n: con esta herramienta no es f√°cil exportar <em>todas</em> las p√°ginas si son muchas, y podr√≠a haber l√≠mites en cantidad de p√°ginas.</li>
</ul>
</li>
<li>
<p><strong>Si tuvieras acceso al servidor</strong></p>
<ul>
<li>
<p>Si vos o alguien que conozcas administra esa instancia de MediaWiki, pod√©s usar el script <code>dumpBackup.php</code> que viene con MediaWiki para volcar toda la wiki en XML. (<a href="https://www.mediawiki.org/wiki/Manual%3ADumpBackup.php/es?utm_source=chatgpt.com" title="Manual:dumpBackup.php - MediaWiki">MediaWiki</a>)</p>
</li>
<li>
<p>Ejemplo:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>php maintenance/run.php dumpBackup --full &gt; dump_completo.xml
</span></span></code></pre></div></li>
<li>
<p>Opcionalmente, incluir archivos subidos con <code>--include-files --uploads</code>. (<a href="https://www.mediawiki.org/wiki/Manual%3ADumpBackup.php/es?utm_source=chatgpt.com" title="Manual:dumpBackup.php - MediaWiki">MediaWiki</a>)</p>
</li>
<li>
<p>Este m√©todo es el m√°s ‚Äúlimpio‚Äù, porque genera un volcado estructurado con todas las p√°ginas y sus revisiones.</p>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="-qu√©-hacer-si-no-hay-un-dump-p√∫blico">‚úÖ Qu√© hacer si no hay un dump p√∫blico</h2>
<ul>
<li>Pod√©s <strong>preguntar a los administradores</strong> de incels.wiki si tienen un dump XML para compartir.</li>
<li>Si no te responden, la opci√≥n con WikiTeam3 es probablemente la m√°s ‚Äúrespetuosa‚Äù y t√©cnica para generar un dump por tu cuenta, usando la API p√∫blica.</li>
<li>Ten√© en cuenta las <strong>cuestiones legales y de licencia</strong>: asegurate de que la licencia del contenido permita que hagas un dump y lo uses para lo que quer√©s hacer.</li>
</ul>
<hr>
<p>Si quer√©s, puedo chequear <strong>en Internet Archive</strong> o en otros repositorios para ver si hay ya un dump de incels.wiki disponible p√∫blicamente, y te comparto el enlace si existe. ¬øTe parece bien hacer eso?</p>

</div>


      </div>
    </section>
  </section><script 
src="/quiz/quizdown.js">
</script>
<script 
src="/quiz/quizdownKatex.js">
</script>
<script 
src="/quiz/quizdownHighlight.js">
</script>
<script>quizdown.register(quizdownHighlight).register(quizdownKatex).init()</script> 
<footer class="footer">
  <div class="content has-text-centered">
    
    
    <p>
      
      <a class="" href="https://imlauera.github.io/index.xml" target="_blank">
        <span>
          RSS
        </span>
      </a>
      
      | <a href="https://imlauera.github.io" target="_blank">Andres Imlauer.</a> 

      
      
    </p>
    
  </div>




<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]} })
</script>
</footer>


</body>
</html>
